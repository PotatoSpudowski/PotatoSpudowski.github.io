<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on GradientDissent</title>
    <link>https://potatospudowski.github.io/posts/</link>
    <description>Recent content in Posts on GradientDissent</description>
    <image>
      <url>https://potatospudowski.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://potatospudowski.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 31 Oct 2022 15:16:19 +0530</lastBuildDate><atom:link href="https://potatospudowski.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Understanding Transformers! (Part 1: Model Architecture)</title>
      <link>https://potatospudowski.github.io/posts/attention/</link>
      <pubDate>Mon, 31 Oct 2022 15:16:19 +0530</pubDate>
      
      <guid>https://potatospudowski.github.io/posts/attention/</guid>
      <description>In the past, we&amp;rsquo;ve had different architectures for different modalities of data like CNNs for Images, RNNs for Text and GNNs for Graphs. Recently we have seen the adoption of Transformers for processing all types of data modalities. Transformers can be thought of like general purpose trainable architecture. Since the adoption of transformers has been growing so rapidly, It might be a good idea to revisit the original paper.
Introduction In sequence modelling and transduction problems, recurrent neural networks, and in particular extended short-term memory and gated recurrent neural networks, have become standard.</description>
    </item>
    
    <item>
      <title>Understanding the mathematical foundations and applications of Graph Convolutional Networks</title>
      <link>https://potatospudowski.github.io/posts/gnn/</link>
      <pubDate>Sat, 19 Jun 2021 00:41:42 +0530</pubDate>
      
      <guid>https://potatospudowski.github.io/posts/gnn/</guid>
      <description>Recent advances in neural networks have driven study of data mining and pattern recognition. End-to-end deep learning models including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and autoencoders have breathed new life into traditional machine learning tasks such as object detection, machine translation, and speech recognition.
Deep Learning is effective at uncovering hidden patterns among Euclidean data (images, text, videos). But what about applications that rely on data originating from non-Euclidean domains, which is typically represented as a graph with intricate interdependencies and relationships among objects?</description>
    </item>
    
    <item>
      <title>RUL(Remaining Useful Life) and SOH(State of Health) estimation of Lithium-ion satellite power systems using Support-Vector-Regression</title>
      <link>https://potatospudowski.github.io/posts/rul/</link>
      <pubDate>Mon, 16 Sep 2019 00:41:42 +0530</pubDate>
      
      <guid>https://potatospudowski.github.io/posts/rul/</guid>
      <description>Batteries are a critical part of any satellite&amp;rsquo;s power system.
They are used to provide power:
During launch and after the launch of the satellite till the solar panels are deployed To the spacecraft, its equipment, and payload during the shadow phase For communication and data transfer To maintain the electronics at a specific temperature Batteries with higher gravimetric(higher mass) and volumetric(higher volume) energy densities lead to lesser mass and volume for the power systems and thereby increase payload and mission capabilities.</description>
    </item>
    
  </channel>
</rss>
